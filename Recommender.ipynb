{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def fit(movies_path, reviews_path, latent_features = 15, learning_rate = 0.001, iters = 5):\n",
    "    \"\"\"\n",
    "    fit the recommender to your dataset and also have this save the results\n",
    "    to pull from when you need to make predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    # Read in the data\n",
    "    movies = pd.read_csv(movies_path)\n",
    "    reviews = pd.read_csv(reviews_path)\n",
    "    \n",
    "    # Create user-by-item matrix - nothing to do here\n",
    "    train_user_item = reviews[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "    train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "    train_data_np = np.array(train_data_df)\n",
    "    \n",
    "    \n",
    "    # Set up useful values to be used through the rest of the function\n",
    "    n_users = train_data_np.shape[0]\n",
    "    n_movies = train_data_np.shape[1]\n",
    "    num_ratings = np.count_nonzero(~np.isnan(train_data_np))\n",
    "    \n",
    "    # initialize the user and movie matrices with random values\n",
    "    user_mat = np.random.rand(n_users, latent_features)\n",
    "    movie_mat = np.random.rand(latent_features, n_movies)\n",
    "    \n",
    "    # initialize sse at 0 for first iteration\n",
    "    sse_accum = 0\n",
    "    \n",
    "    # keep track of iteration and MSE\n",
    "    print(\"Optimizaiton Statistics\")\n",
    "    print(\"Iterations | Mean Squared Error \")\n",
    "    \n",
    "    # for each iteration\n",
    "    for iteration in range(iters):\n",
    "\n",
    "        # update our sse\n",
    "        sse_accum = 0\n",
    "        \n",
    "        # For each user-movie pair\n",
    "        for i in range(n_users):\n",
    "            for j in range(n_movies):\n",
    "                \n",
    "                # if the rating exists\n",
    "                if train_data_np[i, j] > 0:\n",
    "                    \n",
    "                    # compute the error as the actual minus the dot product of the user and movie latent features\n",
    "                    diff = train_data_np[i, j] - np.dot(user_mat[i, :], movie_mat[:, j])\n",
    "                    \n",
    "                    # Keep track of the sum of squared errors for the matrix\n",
    "                    sse_accum += diff**2\n",
    "                    \n",
    "                    # update the values in each matrix in the direction of the gradient\n",
    "                    for k in range(latent_features):\n",
    "                        user_mat[i, k] += learning_rate * (2*diff*movie_mat[k, j])\n",
    "                        movie_mat[k, j] += learning_rate * (2*diff*user_mat[i, k])\n",
    "\n",
    "        # print results\n",
    "        print(\"%d \\t\\t %f\" % (iteration+1, sse_accum / num_ratings))\n",
    "        \n",
    "    return user_mat, movie_mat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaiton Statistics\n",
      "Iterations | Mean Squared Error \n",
      "1 \t\t 14.242965\n",
      "2 \t\t 10.917766\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.38091877, 0.66318563, 0.34483564, ..., 0.21072541, 0.08967444,\n",
       "         0.13108305],\n",
       "        [0.6839765 , 0.23386924, 0.65417004, ..., 0.12132513, 0.02744722,\n",
       "         0.27525867],\n",
       "        [0.2205001 , 0.95745904, 0.56990932, ..., 0.26459268, 0.64142633,\n",
       "         0.19139394],\n",
       "        ...,\n",
       "        [0.16630826, 0.21709987, 0.65121239, ..., 0.35416181, 0.19992449,\n",
       "         0.0320086 ],\n",
       "        [0.27611047, 0.17203368, 0.21686036, ..., 0.68470673, 0.29908348,\n",
       "         0.57858831],\n",
       "        [0.56165498, 0.91313142, 0.58034851, ..., 0.73235052, 0.25482396,\n",
       "         0.89422438]]),\n",
       " array([[0.89212487, 0.58005218, 0.76776821, ..., 0.43139757, 0.770534  ,\n",
       "         0.2030816 ],\n",
       "        [0.73659805, 0.56473347, 0.67906327, ..., 0.79942911, 0.02690398,\n",
       "         0.1824379 ],\n",
       "        [0.77233877, 0.71233165, 0.54843072, ..., 0.10303335, 0.18032889,\n",
       "         0.74970433],\n",
       "        ...,\n",
       "        [0.31652091, 0.82639409, 0.40062314, ..., 0.34190206, 0.32291712,\n",
       "         0.49455586],\n",
       "        [0.37448782, 0.87053931, 0.155862  , ..., 0.36453226, 0.94230731,\n",
       "         0.99129083],\n",
       "        [0.46530475, 0.85103887, 0.40630328, ..., 0.73450271, 0.86364491,\n",
       "         0.67990878]]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit('movies_clean.csv', 'train_data.csv', latent_features = 15, learning_rate = 0.001, iters = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       ...,\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan],\n",
       "       [nan, nan, nan, ..., nan, nan, nan]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('train_data.csv')\n",
    "\n",
    "# Create user-by-item matrix - nothing to do here\n",
    "train_user_item = reviews[['user_id', 'movie_id', 'rating', 'timestamp']]\n",
    "train_data_df = train_user_item.groupby(['user_id', 'movie_id'])['rating'].max().unstack()\n",
    "train_data_np = np.array(train_data_df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
